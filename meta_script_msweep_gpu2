#!/bin/bash

dataset=$1
net=$2
pool=$3
number_inits=$4
intermediate_pooling=0000
L=2
if [ $net = fc ]; then
    L=2
elif [ $net = cnn ]; then
    L=4
    if [ $pool = none ]; then
        intermediate_pooling=0000
    else
        intermediate_pooling=1111
    fi
fi
#optimizer=adam
optimizer=sgd
loss=ce
batch_size=1
#sigmaw=1.0
sigmaw=10.0
sigmab=10.0
c=0.0
epochs_after_fit=0
#prefix=new_mother_of_all_msweeps_
#prefix=a2new_mother_of_all_msweeps_
#prefix=test_msweep_
prefix=2gpu_msweep_

export n_gpus=1
#export n_procs=$number_inits
export n_procs=1

#for m in 1 3 11 36 122 407 1357 4516 15026 49999; do
#for m in 1000; do
#for m in 1000 3000 6000 10000 20000 40000; do
#for m in 15026 49999; do
for m in 40000 ; do
#for m in 49999 ; do
echo $m
## msweep boolean 
  #./run_experiment_msweep --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling 
  #./run_experiment_msweep_gpu --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling --kernel_mult 10000
  ./run_experiment_msweep_gpu2 --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling --batch_size $batch_size #--kernel_mult 10000
  #./run_experiment_msweep_gpu1 --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling --kernel_mult 10
done
