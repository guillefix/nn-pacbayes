#!/bin/bash

cd /home_directory/nn-pacbayes

dataset=$1
net=$2
pool=$3
number_inits=$4
intermediate_pooling=0000
L=2
if [ $net = fc ]; then
    L=2
elif [ $net = cnn ]; then
    L=4
    if [ $pool = none ]; then
        intermediate_pooling=0000
    else
        intermediate_pooling=1111
    fi
fi
optimizer=adam
#optimizer=sgd
batch_size=32
loss=ce
#sigmaw=1.0
sigmaw=1.41
sigmab=0.1
c=0.0
epochs_after_fit=0
#prefix=new_mother_of_all_msweeps_
#prefix=a2new_mother_of_all_msweeps_
#prefix=test_msweep_
prefix=grandmother_of_all_msweeps_

export n_gpus=8
export n_procs=$number_inits

#for m in 1 3 11 36 122 407 1357 4516 15026 40000; do
#for m in 15026 40000; do
for m in $5; do
#for m in 1000; do
#for m in 1000 3000 6000 10000 20000 40000; do
#for m in 15026 49999; do
#for m in 49999 ; do
echo $m
## msweep boolean 
  #./run_experiment_msweep --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling 
  #./run_experiment_msweep_gpu --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling --kernel_mult 10000
  ./run_experiment_msweep_gpu --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling --batch_size $batch_size --normalize_kernel --kernel_mult 1000
  #./run_experiment_msweep_gpu1 --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 0.1 --epochs_after_fit $epochs_after_fit -loss $loss --optimizer $optimizer --use_empirical_K --intermediate_pooling $intermediate_pooling --kernel_mult 10
done
