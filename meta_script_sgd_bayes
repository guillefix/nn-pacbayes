#!/bin/bash

#export PYTHONPATH="/home_directory/.local/lib/python3.5/site-packages/:/usr/local/lib/python3.5/dist-packages/"
#export PYTHONPATH=""

m=20000
dataset=mnist
prefix=adam_ce_chris_unnormalized_
#prefix=langevin_ce_run_
sigmaw=1.0
sigmab=0.0357
n_gpus=0
optimizer=adam
#optimizer=langevin
loss=ce
L=2 # number of layers
batch_size=128
layer_width=512
#epochs_after_fit=64
epochs_after_fit=1
prefix=${prefix}${m}_${layer_width}_${L}_${batch_size}_${optimizer}_${loss}_${epochs_after_fit}_

pool=none
net=fc
c=0
export n_gpus=$n_gpus
export n_procs=100
#export n_procs=2

#for net in resnet50; do 
#for net in vgg19 vgg16 resnet50 resnet101 resnet152 resnetv2_50 resnetv2_101 resnetv2_152 resnext50 resnext101 densenet121 densenet169 densenet201 mobilenetv2 nasnet; do 
    #echo $net
#./run_experiment_sgd_bayes --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --label_corruption $c --n_gpus $n_gpus --pooling $pool --number_inits 2 --optimizer ${optimizer} --loss $loss --zero_one --ignore_non_fit --batch_size $batch_size --layer_width $layer_width --epochs_after_fit $epochs_after_fit $@

addqueue -n $n_procs -m 4 -s './run_experiment_sgd_bayes --prefix '${prefix}' --m '${m}' --dataset '${dataset}' --network '${net}' --number_layers '${L}' --training --sigmaw '${sigmaw}' --sigmab '${sigmab}' --n_gpus '${n_gpus}' --pooling '${pool}' --loss '${loss}' --optimizer '${optimizer}' --number_inits 600000 --ignore_non_fit --batch_size '${batch_size}' --layer_width '${layer_width}' --epochs_after_fit '${epochs_after_fit}' --zero_one'
#done
