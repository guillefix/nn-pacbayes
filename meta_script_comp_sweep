#!/bin/bash


m=1000
#dataset=KMNIST
dataset=mnist
#net=vgg16 
net=cnn
L=4 
pool=none
prefix=new_comp_sweep_
sigmaw=2.0
sigmab=0.0

n_gpus=1
export n_gpus=$n_gpus
c=0


#for c in 0.7 0.8 0.9 1 2 3 4 5; do
for c in 0.0 0.1 0.2 0.3 0.4; do
#for net in vgg19 vgg16 resnet50 resnet101 resnet152 resnetv2_50 resnetv2_101 resnetv2_152 resnext50 resnext101 densenet121 densenet169 densenet201 mobilenetv2 nasnet; do 
#for net in vgg19 vgg16 resnet50 resnet101 resnet152 resnetv2_50 resnetv2_101 resnetv2_152; do 
#for net in resnext50 resnext101 densenet121 densenet169 densenet201 mobilenetv2 nasnet; do 
    ./run_experiment --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training -sigmaw $sigmaw -sigmab $sigmab --corruption $c --n_gpus $n_gpus --compute_bound --pooling $pool --n_samples_repeats 2.0 #--use_empirical_K
	# ./$py NN_train.py --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training -sigmaw $sigmaw -sigmab $sigmab --confusion $c --ngpus $n_gpus --compute_bound --pooling $pool --n_samples_repeats 2.0 --use_empirical_K
done
