#!/bin/bash

m=100
dataset=KMNIST
#boolfun=00001110110011111001111111001111000000000000000000000000000000000000000001001100000000001101110100000000000000000000000000000000
boolfun_comp=84.0
net=fc
L=2
optimizer=sgd
loss=ce
sigmaw=1.41
#sigmaw=50.0
sigmab=0.0
pool=none
c=0.0
number_inits=8
epochs_after_fit=0
prefix=test_

export n_gpus=0
export n_procs=8


for rep in `seq 1 1`; do
echo $rep

  #./run_experiment2 --prefix $prefix --m $m --threshold $t --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 2.0 --boolfun_comp $boolfun_comp --boolfun $boolfun --epochs_after_fit $epochs_after_fit -loss $loss #--use_empirical_K --intermediate_pooling 1111 --intermediate_pooling_type none
  ./run_experiment --prefix $prefix --m $m --dataset $dataset --network $net --number_layers $L --training --sigmaw $sigmaw --sigmab $sigmab --confusion $c --n_gpus $n_gpus --pooling $pool --number_inits $number_inits --n_samples_repeats 2.0 --epochs_after_fit $epochs_after_fit -loss $loss --centering --nn_random_labels


done
